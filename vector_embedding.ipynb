{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1sSOaeqi9j3YjJCSOfOLF9chwOBW6lc1g","authorship_tag":"ABX9TyNi0SyRuvdSNdnkLZDxJ9Rc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9ea4802221d44167a6233ea3175fcd6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1a2fae51e9542e1ba58fa7eb03a88f4","IPY_MODEL_8678086282854e7c92a04980aa570c29","IPY_MODEL_78e750c788294fa18229e3ed3922bfd1"],"layout":"IPY_MODEL_7921421d0c5542fc9ac1b4268e15ed03"}},"f1a2fae51e9542e1ba58fa7eb03a88f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11fb7e2a02204e749bb7f92ea0044e58","placeholder":"​","style":"IPY_MODEL_73c9300d2bb74c0eb1cb18c524530219","value":"tokenizer_config.json: 100%"}},"8678086282854e7c92a04980aa570c29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_953da43ba083434184e994edce05c9ac","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0fabf1f050e41e193e7388645396d45","value":48}},"78e750c788294fa18229e3ed3922bfd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ed7cbfe49824cc0a27fde4dcfbb8bc2","placeholder":"​","style":"IPY_MODEL_a3e1706adc6f4ec985194d8e17c88175","value":" 48.0/48.0 [00:00&lt;00:00, 868B/s]"}},"7921421d0c5542fc9ac1b4268e15ed03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11fb7e2a02204e749bb7f92ea0044e58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73c9300d2bb74c0eb1cb18c524530219":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"953da43ba083434184e994edce05c9ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0fabf1f050e41e193e7388645396d45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ed7cbfe49824cc0a27fde4dcfbb8bc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3e1706adc6f4ec985194d8e17c88175":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e06c96e4e2144460aa1e858c9bda34db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cfd726138ced45eab470bc74f4c7a460","IPY_MODEL_062d165d39eb4893a30f4e5b95cbbeb8","IPY_MODEL_6c2891c69bd344c4bf03bd0be2af900d"],"layout":"IPY_MODEL_ec692ca7d5164313a9ef676a09f40668"}},"cfd726138ced45eab470bc74f4c7a460":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a3e2f0ca4e849b391fc40d531708c7e","placeholder":"​","style":"IPY_MODEL_d17677e7997c47ee83d8b0f1710d852e","value":"vocab.txt: 100%"}},"062d165d39eb4893a30f4e5b95cbbeb8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e9b61b641054998acb41a521558b0a4","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de517d37d747469e9466c71f14b334bb","value":231508}},"6c2891c69bd344c4bf03bd0be2af900d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07caa3d01ad64211b0c2faa62678d780","placeholder":"​","style":"IPY_MODEL_23ef0580534e4e3b9174e823e4336b56","value":" 232k/232k [00:00&lt;00:00, 5.95MB/s]"}},"ec692ca7d5164313a9ef676a09f40668":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a3e2f0ca4e849b391fc40d531708c7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d17677e7997c47ee83d8b0f1710d852e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e9b61b641054998acb41a521558b0a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de517d37d747469e9466c71f14b334bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07caa3d01ad64211b0c2faa62678d780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23ef0580534e4e3b9174e823e4336b56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e08a90e438eb4c0e85c9e1ba1d366564":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb7866841ca7485d9408bbc85135431b","IPY_MODEL_8a4d8abd5e0a4046b43adb19dd6671db","IPY_MODEL_97bb383af4214933a21b2c2e69a9accc"],"layout":"IPY_MODEL_6d6da478249b4751bb5c70a2041faa53"}},"bb7866841ca7485d9408bbc85135431b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7127db0acf14e7aba570b90837a2131","placeholder":"​","style":"IPY_MODEL_8d2ee842daa74660b1431c6d93a0bbf9","value":"tokenizer.json: 100%"}},"8a4d8abd5e0a4046b43adb19dd6671db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b32bf0f9a244383b673cdf96b017905","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0204284f7f24c70822772ec398c7728","value":466062}},"97bb383af4214933a21b2c2e69a9accc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ab65fa365344bbfbab6be79bbfb4c2f","placeholder":"​","style":"IPY_MODEL_62ba208a1ffc4e0cb794a25cccbbe120","value":" 466k/466k [00:00&lt;00:00, 12.8MB/s]"}},"6d6da478249b4751bb5c70a2041faa53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7127db0acf14e7aba570b90837a2131":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d2ee842daa74660b1431c6d93a0bbf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b32bf0f9a244383b673cdf96b017905":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0204284f7f24c70822772ec398c7728":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ab65fa365344bbfbab6be79bbfb4c2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62ba208a1ffc4e0cb794a25cccbbe120":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9795910ee3d467abe13484182aadcbf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5756a9ea60f47d8a46b143a9d3cdc73","IPY_MODEL_0e550590e8dc4b9a8d851a683f31a32f","IPY_MODEL_87fe1eb308e2471faadb4fdbddaa2884"],"layout":"IPY_MODEL_7e2c78ab77ba4910b3712c1e0af16951"}},"f5756a9ea60f47d8a46b143a9d3cdc73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45ab06d8c03a4c97871e45d20dbe6339","placeholder":"​","style":"IPY_MODEL_3d5e9fe8b29b42a4908fb9ed4b0af914","value":"config.json: 100%"}},"0e550590e8dc4b9a8d851a683f31a32f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_882d840c38a54e09bd6d681a78214912","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_546939d1ff514057a3f610445bf1d62b","value":570}},"87fe1eb308e2471faadb4fdbddaa2884":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e1a8ebec6754f8980e12ae8b5ba96b4","placeholder":"​","style":"IPY_MODEL_aef9aee7614b4c6b8745d805d262b30b","value":" 570/570 [00:00&lt;00:00, 15.6kB/s]"}},"7e2c78ab77ba4910b3712c1e0af16951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45ab06d8c03a4c97871e45d20dbe6339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5e9fe8b29b42a4908fb9ed4b0af914":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"882d840c38a54e09bd6d681a78214912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"546939d1ff514057a3f610445bf1d62b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e1a8ebec6754f8980e12ae8b5ba96b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aef9aee7614b4c6b8745d805d262b30b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d9bfd43ba884154be8976fd48c05cde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6b2a0f7ace8445ca07357fb54b0df24","IPY_MODEL_b78c6465e67e4470adf7c8d4b8b62986","IPY_MODEL_df58971bf6cd4f4d99d481ab4d2565b6"],"layout":"IPY_MODEL_2e262c27c93642c59ad022d1c3b835e3"}},"f6b2a0f7ace8445ca07357fb54b0df24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0b3e0e190e0441abb84ac6fd0c7cb0c","placeholder":"​","style":"IPY_MODEL_e3347193cd6544418fb37f04fa4e39aa","value":"model.safetensors: 100%"}},"b78c6465e67e4470adf7c8d4b8b62986":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62530bd82b0249639448eb6637726489","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebc0a0d5bc564278adeaa2dcdea84bdb","value":440449768}},"df58971bf6cd4f4d99d481ab4d2565b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45714c75b2b0451b97ba48002648c2dc","placeholder":"​","style":"IPY_MODEL_2c9647540566454c961b4185acb5069d","value":" 440M/440M [00:06&lt;00:00, 140MB/s]"}},"2e262c27c93642c59ad022d1c3b835e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0b3e0e190e0441abb84ac6fd0c7cb0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3347193cd6544418fb37f04fa4e39aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62530bd82b0249639448eb6637726489":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebc0a0d5bc564278adeaa2dcdea84bdb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45714c75b2b0451b97ba48002648c2dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c9647540566454c961b4185acb5069d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","\n","from string import punctuation\n","from matplotlib import pyplot as plt\n","\n","from sklearn import metrics, mixture, svm\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation, PCA\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","\n","import gensim\n","from gensim.models import word2vec\n","\n","import nltk, string\n","from nltk.corpus import stopwords\n","from nltk.cluster import KMeansClusterer, cosine_distance, euclidean_distance\n","nltk.download('stopwords')\n","nltk.download('punkt')\n"],"metadata":{"id":"GoaHUm70yyMK","executionInfo":{"status":"aborted","timestamp":1711905521093,"user_tz":240,"elapsed":3,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Bag of Words\n","\n","There are many ways to transform text data to numeric vectors. In this task you will try to use two of them. One of the well-known approaches is a bag-of-words representation. To create this transformation, follow the steps:\n","\n","1. Find N most popular words in train corpus and numerate them. Now we have a dictionary of the most popular words.  \n","2. For each title in the corpora create a zero vector with the dimension equals to N.  \n","3. For each text in the corpora iterate over words which are in the dictionary and increase by 1 the corresponding coordinate."],"metadata":{"id":"b-RtWorSz--0"}},{"cell_type":"code","source":["\n","\n","def my_bag_of_words(text, words_to_index):\n","    \"\"\"\n","    text: a string\n","    words_to_index: a list, train corpus words\n","    dict_size: size of the dictionary\n","\n","    return a vector which is a bag-of-words representation of 'text'\n","    \"\"\"\n","\n","    dict_size = len(words_to_index)\n","\n","    result_vector = np.zeros(dict_size)\n","\n","    popular_words = enumerate(set(words_to_index))\n","    words_idx = {w:i for i,w in popular_words}\n","\n","    for text in text.split():\n","        if text in words_idx:\n","            result_vector[words_idx[text]] += 1\n","\n","    return result_vector\n","\n","text = 'hi how are you'\n","words_to_index = ['hi', 'you', 'me', 'are']\n","\n","my_bag_of_words(text, words_to_index)\n"],"metadata":{"id":"9L0O0uuufoRh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xPMgvRKYfoVX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"haAxPoySfoYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nsOiLviDfoa7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0AE3A_6cfodt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Word Vectorization"],"metadata":{"id":"RVCS-f9lz3g0"}},{"cell_type":"markdown","source":["## Word2Vector"],"metadata":{"id":"SS30pMyrfhtO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ohk8r_hyynHg"},"outputs":[],"source":["\n","def train_wordvec(docs, vector_size):\n","    # Tokenize docs into tokens and remove punctuations\n","    documents = []\n","    for doc in docs:\n","        tokens = [word.strip(string.punctuation) for word in doc.lower().split()]\n","        documents.append(tokens)\n","\n","    # Train word vectors using gensim package\n","    model = gensim.models.Word2Vec(documents, vector_size=vector_size, window=5, min_count=1, workers=4)\n","\n","    return model\n","\n","def generate_doc_vector(docs, wv_model):\n","\n","\n","    # Tokenize each document into tokens\n","    tokenized_docs = []\n","    for doc in docs:\n","        tokens = [word.strip(string.punctuation) for word in doc.lower().split()]\n","        tokenized_docs.append(tokens)\n","\n","    # Generate document vectors\n","    doc_vectors = []\n","    for doc in tokenized_docs:\n","        vectors = [wv_model.wv[token] for token in doc if token in wv_model.wv]\n","        if len(vectors) > 0:\n","            doc_vector = np.mean(vectors, axis=0)\n","        else:\n","            doc_vector = np.zeros(wv_model.vector_size)\n","        doc_vectors.append(doc_vector)\n","\n","    vectors = np.array(doc_vectors)\n","    # Return document vectors as a numpy array\n","    return vectors\n"]},{"cell_type":"code","source":["# Here we will use our previous chatgpt dataset\n","data=pd.read_csv(\"/content/drive/MyDrive/Notebooks/nlp-data-mining/text_clustering_methods/detect.csv\")\n","x_train, x_test, y_train, y_test = train_test_split(data[\"text\"], data[\"label\"], test_size=0.2,random_state=0)\n","\n","data.head()\n","\n","documents=[\n","            [\n","                token.strip(punctuation).strip()\n","                 for token in nltk.word_tokenize(doc.lower())\n","                    if token not in punctuation and len(token.strip(punctuation).strip()) >= 2\n","            ]\n","            for doc in data[\"text\"]\n","        ]\n","\n","# use function\n","model = gensim.models.Word2Vec(documents, vector_size=300, window=5, min_count=5, workers=4)\n"],"metadata":{"id":"0_MWnh7aytvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# print(model.wv['movie'], '\\n')\n","\n","# Top {n} word(s) with high relevance to {positive_vector} and low relevance to {negative_vector}: {top_n}\n","wv_correlation = lambda positive_vector=[], negative_vector=[], n=5: model.wv.most_similar(positive=positive_vector, negative=negative_vector, topn=n)\n","print(wv_correlation(['sound','music']), '\\n')\n","print(wv_correlation(['sound','music'], ['film']), '\\n')\n","\n","\n","# similarity between two tokens\n","wv_pos_sim = lambda token_a, token_b: model.wv.similarity(token_a, token_b)\n","print(wv_pos_sim('brass', 'acoustic'), '\\n')\n","print(wv_pos_sim('movie','city'), '\\n')\n","\n","wv_outlier = lambda word_vector: model.wv.doesnt_match(word_vector)\n","print(wv_outlier([\"sound\", \"music\", \"graphics\", \"actor\", \"book\"]))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imtS7jNayuvx","executionInfo":{"status":"ok","timestamp":1711860021978,"user_tz":240,"elapsed":2,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"ebd8cb69-659b-4e55-c0ba-4c449f9fa17f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('dance', 0.8091345429420471), ('pop', 0.8018935918807983), ('scene', 0.8004364371299744), ('recording', 0.7784169912338257), ('soul', 0.77668297290802)] \n","\n","[('mix', 0.6810025572776794), ('brass', 0.6776862144470215), ('acoustic', 0.6772572994232178), ('punk', 0.6729581356048584), ('influences', 0.664824903011322)] \n","\n","0.77276725 \n","\n","-0.11576279 \n","\n","actor\n"]}]},{"cell_type":"markdown","source":["## Pretrained Word Vectors\n","- Google published pre-trained 300-dimensional vectors for 3 million words and phrases that were trained on Google News dataset (about 100 billion words)(https://code.google.com/archive/p/word2vec/)\n","- GloVe (Global Vectors for Word Representation): Pretained word vectors from different data sources provided by Standford https://nlp.stanford.edu/projects/glove/\n","- FastText by Facebook https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md"],"metadata":{"id":"zlJX45JZfm6Y"}},{"cell_type":"code","source":["import gensim\n","model = gensim.models.KeyedVectors.load_word2vec_format(\n","                                    '/content/drive/MyDrive/Notebooks/nlp-data-mining/text_clustering_methods/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","\n","model.most_similar(positive=['women','king'], negative='man')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cdQNykOgvtz","executionInfo":{"status":"ok","timestamp":1711906031657,"user_tz":240,"elapsed":113309,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"51ee8a5e-3f6d-4cb2-a1df-1119096da0e5"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('queen', 0.4827326238155365),\n"," ('queens', 0.466781347990036),\n"," ('kumaris', 0.4653734564781189),\n"," ('kings', 0.4558638632297516),\n"," ('womens', 0.422832190990448),\n"," ('princes', 0.4176960587501526),\n"," ('Al_Anqari', 0.41725507378578186),\n"," ('concubines', 0.4011078476905823),\n"," ('monarch', 0.3962482810020447),\n"," ('monarchy', 0.39430150389671326)]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Load the BERT tokenizer.\n","\n","#!pip install transformers\n","import torch\n","from transformers import BertTokenizer, BertModel, pipeline\n","\n","\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","text = \"Here is the sentence I want embeddings for.\"\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\n","\n","# Tokenize our sentence with the BERT tokenizer.\n","tokenized_text = tokenizer.tokenize(marked_text)\n","\n","# Print out the tokens.\n","print (tokenized_text)\n","#The original word has been split into smaller subwords and characters.\n","#The two hash signs preceding some of these subwords are just our tokenizer’s way to denote that this subword\n","# or character is part of a larger word and preceded by another subword.\n","# this way some contextual meaning of the original word will be retained.\n","\n","# check out contents of BERT’s vocabulary\n","list(tokenizer.vocab.keys())[5000:5020]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":667,"referenced_widgets":["9ea4802221d44167a6233ea3175fcd6a","f1a2fae51e9542e1ba58fa7eb03a88f4","8678086282854e7c92a04980aa570c29","78e750c788294fa18229e3ed3922bfd1","7921421d0c5542fc9ac1b4268e15ed03","11fb7e2a02204e749bb7f92ea0044e58","73c9300d2bb74c0eb1cb18c524530219","953da43ba083434184e994edce05c9ac","e0fabf1f050e41e193e7388645396d45","2ed7cbfe49824cc0a27fde4dcfbb8bc2","a3e1706adc6f4ec985194d8e17c88175","e06c96e4e2144460aa1e858c9bda34db","cfd726138ced45eab470bc74f4c7a460","062d165d39eb4893a30f4e5b95cbbeb8","6c2891c69bd344c4bf03bd0be2af900d","ec692ca7d5164313a9ef676a09f40668","4a3e2f0ca4e849b391fc40d531708c7e","d17677e7997c47ee83d8b0f1710d852e","1e9b61b641054998acb41a521558b0a4","de517d37d747469e9466c71f14b334bb","07caa3d01ad64211b0c2faa62678d780","23ef0580534e4e3b9174e823e4336b56","e08a90e438eb4c0e85c9e1ba1d366564","bb7866841ca7485d9408bbc85135431b","8a4d8abd5e0a4046b43adb19dd6671db","97bb383af4214933a21b2c2e69a9accc","6d6da478249b4751bb5c70a2041faa53","c7127db0acf14e7aba570b90837a2131","8d2ee842daa74660b1431c6d93a0bbf9","2b32bf0f9a244383b673cdf96b017905","e0204284f7f24c70822772ec398c7728","7ab65fa365344bbfbab6be79bbfb4c2f","62ba208a1ffc4e0cb794a25cccbbe120","d9795910ee3d467abe13484182aadcbf","f5756a9ea60f47d8a46b143a9d3cdc73","0e550590e8dc4b9a8d851a683f31a32f","87fe1eb308e2471faadb4fdbddaa2884","7e2c78ab77ba4910b3712c1e0af16951","45ab06d8c03a4c97871e45d20dbe6339","3d5e9fe8b29b42a4908fb9ed4b0af914","882d840c38a54e09bd6d681a78214912","546939d1ff514057a3f610445bf1d62b","9e1a8ebec6754f8980e12ae8b5ba96b4","aef9aee7614b4c6b8745d805d262b30b"]},"id":"h3DOzdUPhNFh","executionInfo":{"status":"ok","timestamp":1711906161438,"user_tz":240,"elapsed":21438,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"b91210c6-bb2b-4df9-faba-600946b75029"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea4802221d44167a6233ea3175fcd6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e06c96e4e2144460aa1e858c9bda34db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e08a90e438eb4c0e85c9e1ba1d366564"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9795910ee3d467abe13484182aadcbf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['[CLS]', 'here', 'is', 'the', 'sentence', 'i', 'want', 'em', '##bed', '##ding', '##s', 'for', '.', '[SEP]']\n"]},{"output_type":"execute_result","data":{"text/plain":["['knight',\n"," 'lap',\n"," 'survey',\n"," 'ma',\n"," '##ow',\n"," 'noise',\n"," 'billy',\n"," '##ium',\n"," 'shooting',\n"," 'guide',\n"," 'bedroom',\n"," 'priest',\n"," 'resistance',\n"," 'motor',\n"," 'homes',\n"," 'sounded',\n"," 'giant',\n"," '##mer',\n"," '150',\n"," 'scenes']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["\n","unmasker = pipeline('fill-mask', model='bert-base-uncased')\n","unmasker(\"Artificial Intelligence [MASK] take over the world.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":481,"referenced_widgets":["0d9bfd43ba884154be8976fd48c05cde","f6b2a0f7ace8445ca07357fb54b0df24","b78c6465e67e4470adf7c8d4b8b62986","df58971bf6cd4f4d99d481ab4d2565b6","2e262c27c93642c59ad022d1c3b835e3","d0b3e0e190e0441abb84ac6fd0c7cb0c","e3347193cd6544418fb37f04fa4e39aa","62530bd82b0249639448eb6637726489","ebc0a0d5bc564278adeaa2dcdea84bdb","45714c75b2b0451b97ba48002648c2dc","2c9647540566454c961b4185acb5069d"]},"id":"3g0My0RVjCuy","executionInfo":{"status":"ok","timestamp":1711906259344,"user_tz":240,"elapsed":10443,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"3f2dbb70-a88a-4038-f852-025fe2e75307"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d9bfd43ba884154be8976fd48c05cde"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.3182409107685089,\n","  'token': 2064,\n","  'token_str': 'can',\n","  'sequence': 'artificial intelligence can take over the world.'},\n"," {'score': 0.18299664556980133,\n","  'token': 2097,\n","  'token_str': 'will',\n","  'sequence': 'artificial intelligence will take over the world.'},\n"," {'score': 0.05600148066878319,\n","  'token': 2000,\n","  'token_str': 'to',\n","  'sequence': 'artificial intelligence to take over the world.'},\n"," {'score': 0.04519490897655487,\n","  'token': 2015,\n","  'token_str': '##s',\n","  'sequence': 'artificial intelligences take over the world.'},\n"," {'score': 0.045153163373470306,\n","  'token': 2052,\n","  'token_str': 'would',\n","  'sequence': 'artificial intelligence would take over the world.'}]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["\n","import pandas as pd\n","import nltk,string\n","nltk.download('punkt')\n","# Load data\n","data=pd.read_csv('/content/drive/MyDrive/Notebooks/data/amazon_review_large.csv')\n","data.columns=['label','text']\n","data\n","\n","# tokenize each document into a list of unigrams\n","# strip punctuations and leading/trailing spaces from unigrams\n","# only unigrams with 2 or more characters are taken\n","sentences=[ [token.strip(string.punctuation).strip() \\\n","             for token in nltk.word_tokenize(doc.lower()) \\\n","                 if token not in string.punctuation and \\\n","                 len(token.strip(string.punctuation).strip())>=2]\\\n","             for doc in data[\"text\"]]\n","print(sentences[0:2])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Uml3v31kOLQ","executionInfo":{"status":"ok","timestamp":1711906406514,"user_tz":240,"elapsed":21460,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"f3981baf-04fc-45a6-df16-cde403aa2cf5"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["[['this', 'is', 'little', 'longer', 'and', 'more', 'detailed', 'than', 'the', 'first', 'two', 'books', 'in', 'the', 'series', 'however', 'have', 'enjoyed', 'each', 'new', 'aspect', 'of', 'the', 'exciting', 'fantasy', 'universe'], ['only', 'michelle', 'branch', 'save', 'this', 'album', 'all', 'guys', 'play', 'along', 'with', 'unenthusiastic', 'beat', 'even', 'karl']]\n"]}]},{"cell_type":"code","source":["# use our data\n","data=data.iloc[:100]\n","sentences=data[\"text\"].values\n","# Print the original sentence.\n","print(' Original: ', sentences[0])\n","\n","# Print the sentence split into tokens.\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","\n","# Print the sentence mapped to token ids.\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n","\n","input_ids = []\n","attention_masks = []\n","max_len =50\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = max_len,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","\n","    # Add the encoded sentence to the list.\n","    input_ids.append(encoded_dict['input_ids'])\n","\n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Psr6sAjVjSlb","executionInfo":{"status":"ok","timestamp":1711906410944,"user_tz":240,"elapsed":333,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"463d497e-2afc-497f-9305-ab51197b1487"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":[" Original:  This is a little longer and more detailed than the first two books in the series. However, I have enjoyed each new aspect of the exciting fantasy universe.\n","Tokenized:  ['this', 'is', 'a', 'little', 'longer', 'and', 'more', 'detailed', 'than', 'the', 'first', 'two', 'books', 'in', 'the', 'series', '.', 'however', ',', 'i', 'have', 'enjoyed', 'each', 'new', 'aspect', 'of', 'the', 'exciting', 'fantasy', 'universe', '.']\n","Token IDs:  [2023, 2003, 1037, 2210, 2936, 1998, 2062, 6851, 2084, 1996, 2034, 2048, 2808, 1999, 1996, 2186, 1012, 2174, 1010, 1045, 2031, 5632, 2169, 2047, 7814, 1997, 1996, 10990, 5913, 5304, 1012]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["\n","\n","# Load pre-trained model (weights)\n","bert_model = BertModel.from_pretrained('bert-base-uncased',\n","                                    #output_attentions = False, # Whether the model returns attentions weights.\n","                                    output_hidden_states = True, # Whether the model returns all hidden-states.\n","                                  )\n","\n","## Put the model in \"evaluation\" mode, meaning feed-forward operation.\n","bert_model.eval()\n","with torch.no_grad():\n","\n","    outputs = bert_model(input_ids)\n","    #the third item will be the hidden states from all layers.\n","    hidden_states = outputs[2]\n","\n","print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n","layer_i = 0\n","print (\"Number of batches:\", len(hidden_states[layer_i]))\n","#The second dimension, the batch size, is used when submitting multiple sentences to the model at once\n","batch_i = 0\n","print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n","token_i = 0\n","print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n","print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n","layer_i = 0\n","print (\"Number of batches:\", len(hidden_states[layer_i]))\n","#The second dimension, the batch size, is used when submitting multiple sentences to the model at once\n","batch_i = 0\n","print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n","token_i = 0\n","print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n","\n","\n","\n","# get the last four layers\n","token_embeddings = torch.stack(hidden_states[-4:], dim=0)\n","print(token_embeddings.size())\n","\n","# permute axis\n","token_embeddings = token_embeddings.permute(1,2,0,3)\n","print(token_embeddings.size())\n","\n","# take the mean of the last 4 layers\n","token_embeddings = token_embeddings.mean(axis=2)\n","print(token_embeddings.size())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xodSHUgojtre","executionInfo":{"status":"ok","timestamp":1711906430524,"user_tz":240,"elapsed":16502,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"a5bbc4e9-f370-4308-cf66-599f1ba24403"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"output_type":"stream","name":"stdout","text":["Number of layers: 13   (initial embeddings + 12 BERT layers)\n","Number of batches: 100\n","Number of tokens: 50\n","Number of hidden units: 768\n","Number of layers: 13   (initial embeddings + 12 BERT layers)\n","Number of batches: 100\n","Number of tokens: 50\n","Number of hidden units: 768\n","torch.Size([4, 100, 50, 768])\n","torch.Size([100, 50, 4, 768])\n","torch.Size([100, 50, 768])\n"]}]},{"cell_type":"code","source":["token_embeddings[0,0,:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iIv4CcxWj9E-","executionInfo":{"status":"ok","timestamp":1711906441284,"user_tz":240,"elapsed":162,"user":{"displayName":"Cameron C.","userId":"04349246908971071571"}},"outputId":"b80fb235-344b-4814-821c-2f142f88f819"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-1.1674e-01, -5.8241e-01,  4.6175e-02, -2.3729e-01, -5.1516e-01,\n","        -1.8817e-01,  3.6290e-01,  2.7166e-01,  1.7761e-01, -8.4111e-01,\n","        -1.9935e-01,  3.3611e-01,  2.5841e-01,  5.8463e-01,  7.7076e-01,\n","         4.6129e-01, -1.8080e-01,  5.4306e-01,  3.8711e-01, -2.4097e-01,\n","         3.7831e-01,  4.6802e-01,  8.4769e-01,  1.0741e-01,  1.6989e-01,\n","        -2.8467e-01, -5.7680e-01, -1.5120e-01, -4.5195e-01,  7.4451e-02,\n","        -4.1504e-01,  6.1160e-02,  3.2209e-02,  2.4624e-01,  6.4040e-01,\n","        -2.9038e-01, -1.0277e-02, -2.5516e-01,  1.7088e-01,  3.1873e-02,\n","        -4.9831e-01, -2.2552e-01,  4.3180e-01, -2.0207e-01,  3.9851e-01,\n","        -3.9309e-01, -4.3959e+00,  1.9462e-01, -2.2815e-01,  2.0750e-01,\n","         2.5107e-01, -3.9301e-01,  6.9134e-02,  2.4547e-01,  5.4014e-01,\n","         8.6356e-01, -4.0756e-01, -4.7488e-01,  5.7281e-01,  1.6575e-04,\n","         3.8241e-01,  2.6872e-01, -3.5878e-01, -1.2718e-01, -2.0059e-01,\n","         1.6424e-01,  5.5433e-01, -1.9884e-01, -3.5233e-01,  1.1113e+00,\n","         2.6240e-01,  4.8934e-01,  1.2434e-01,  5.2278e-01, -2.4246e-02,\n","        -5.6428e-01, -4.3149e-01,  6.5885e-01, -6.5949e-01, -2.8488e-01,\n","        -7.7720e-02,  2.2847e-01,  3.4881e-01, -3.0991e-01,  4.8294e-01,\n","         5.2094e-01,  1.3239e-01, -2.6545e-01,  1.3792e-01,  1.4785e-01,\n","        -1.2238e-01, -8.6928e-02, -5.9070e-01, -7.3859e-02,  8.4208e-01,\n","        -3.9755e-01, -3.0791e-01, -4.0577e-01, -3.2322e-01,  8.1665e-01,\n","         2.9392e-01,  8.4824e-01, -4.0189e-02, -8.0217e-01,  6.8353e-02,\n","        -1.5561e-02, -3.5759e-01, -2.4667e-01, -1.2448e-01, -2.4065e-01,\n","         2.1959e-01,  1.3923e-01,  3.7884e-02, -4.1337e-01,  1.7500e-01,\n","        -1.5709e-01,  3.4158e-01,  1.1842e-01,  3.9512e-01, -4.2584e-01,\n","        -1.4451e-01, -4.2437e-02,  2.8442e-02, -4.6329e-02,  3.4262e-01,\n","         7.7092e-02,  2.2574e-01, -1.1013e+00,  2.8116e-01, -1.5779e-02,\n","         2.1027e-01,  1.1082e-01, -5.8561e-01,  9.1118e-02, -6.2084e-02,\n","         3.1869e-01,  1.0569e-01,  7.8224e-02, -6.8364e-01, -6.5968e-02,\n","        -1.0196e+00, -7.7983e-01, -1.3280e+00,  1.6331e-01,  7.0948e-01,\n","         7.0543e-01,  1.2083e-01,  7.0610e-01, -6.2007e-01,  4.9422e-02,\n","        -2.8592e-01, -1.2609e-01, -6.9524e-01, -2.0708e-01, -2.9369e-01,\n","        -6.7857e-01, -9.3166e-02,  1.2180e-01, -2.1345e-02,  3.7166e-01,\n","        -6.0007e-02,  1.0312e-01,  4.7896e-04,  1.7923e-01,  4.7600e-01,\n","         2.6793e-01,  5.6641e-01,  7.9208e-01,  2.6304e-01, -1.3294e-01,\n","         6.6942e-02, -7.6229e-02,  2.7678e-01, -3.9513e-01,  5.7275e-02,\n","         5.9705e-01,  5.5531e-02,  1.9647e-01, -3.2920e-02, -1.5051e-01,\n","        -1.8463e-01,  6.4389e-02,  1.0788e-02,  3.4367e-01,  5.6598e-01,\n","         2.8288e-01,  1.7805e-01,  4.0240e-01, -2.8866e-02,  6.2308e-01,\n","        -7.7084e-01, -2.7658e-01,  1.3398e-01,  2.2498e-01,  5.5600e-01,\n","        -8.0981e-02, -1.8217e-02, -2.2449e-02, -4.6838e-02, -4.6590e-01,\n","         1.4388e-01,  4.5222e-01,  4.4109e-02,  4.3660e-01, -3.1193e-01,\n","         2.0806e+00,  6.1539e-02,  6.8025e-03,  9.4154e-02, -4.5280e-02,\n","        -8.5353e-01, -3.0534e-01, -5.3047e-01,  7.0621e-01, -2.6646e-01,\n","        -4.1092e-02,  1.0881e-01, -4.8054e-01, -2.2758e-02, -8.8372e-02,\n","        -1.9446e-01,  2.5115e-01, -3.4569e-01,  2.6481e-01, -4.4826e-01,\n","        -1.5168e-01, -4.2276e-01, -6.7008e-02,  1.2732e-01, -1.7061e+00,\n","         2.3185e-02, -6.8555e-01, -3.6767e-01,  6.8062e-02,  5.8536e-02,\n","         4.0815e-01, -4.4172e-02, -7.2170e-01, -1.4471e-01, -2.4753e-01,\n","        -2.4356e-01,  5.7488e-02,  6.6991e-01,  2.2269e-01,  4.4875e-02,\n","         4.7302e-02, -2.6120e-01,  7.1397e-02,  6.1978e-02,  4.1830e-02,\n","         3.7355e-01,  2.3525e-01,  1.7577e-01,  1.2959e-01,  3.6105e-01,\n","         3.2903e-01, -2.6871e-01,  1.2853e-01, -6.4410e-01, -6.1203e-01,\n","        -2.5680e-01, -3.1937e-01, -4.6457e-01,  2.1306e-01, -2.4077e-01,\n","        -1.3629e-01,  5.3826e-01, -1.7773e-01,  4.6255e-01, -2.5472e-02,\n","        -2.9789e-01, -2.9855e-01, -6.8101e-01,  2.4737e-01, -1.0669e-01,\n","        -5.2193e-01,  2.0598e-01, -1.8339e-02,  1.4854e-01, -3.0242e-01,\n","         5.8229e-01,  4.4244e-02, -5.9484e-01,  1.6363e-01, -3.8587e-05,\n","        -4.1834e-01,  4.3708e-01, -5.3040e-01,  2.0828e-01,  6.0353e-02,\n","        -5.2832e-01,  6.8440e-02, -7.3565e-01, -9.7321e-02,  2.5380e-01,\n","        -3.1189e-01,  2.9857e-01,  3.5716e-01,  3.0574e-01, -2.4202e-01,\n","        -1.2856e-01,  1.7648e-01,  4.7529e-02,  2.2718e-01, -1.5742e-01,\n","         1.0190e-01, -4.6351e-01, -1.0159e-01, -6.5436e+00,  2.7761e-01,\n","        -2.5390e-01, -1.6065e-01, -8.4698e-02,  4.8783e-01,  9.5073e-01,\n","         2.8609e-01, -1.8638e-01,  2.0725e-01,  8.6597e-02,  4.0167e-01,\n","         3.8852e-01, -5.6644e-01, -2.3602e-01, -1.9147e-01,  9.3460e-01,\n","        -3.4325e-01,  2.0332e-01,  2.8043e-01, -2.7991e-01, -1.6388e-01,\n","        -1.6414e-01,  1.6022e-02,  2.6993e-01, -9.6276e-03, -8.8753e-01,\n","        -2.2775e-01,  2.1182e-01,  1.6237e-01,  1.8210e-01, -9.9728e-01,\n","        -6.9461e-02, -1.5388e-01, -4.4140e-01, -2.8296e-01, -1.0347e-01,\n","         7.9048e-02,  9.1998e-01, -5.7313e-02,  2.6997e-01, -1.1960e-01,\n","        -4.8293e-01,  2.8153e-02,  5.9156e-01, -5.2177e-01,  5.1019e-01,\n","         6.0029e-01,  2.0945e-01,  9.6613e-01,  4.0967e-02,  2.3941e-01,\n","         1.2487e+00, -3.4248e-01,  2.2188e-01,  1.0250e-01,  1.0232e-01,\n","         3.6594e-01, -4.3221e-01, -9.9286e-02,  1.0759e+00,  1.3798e-01,\n","         3.2816e-02,  1.7804e-01,  4.4478e-01, -6.1109e-01,  7.0312e-01,\n","        -6.5474e-01, -1.0161e+00, -4.1644e-03, -1.1553e+00,  1.8842e-01,\n","        -4.0396e-01, -3.3793e+00,  2.2695e-01, -2.2415e-01, -2.5975e-01,\n","         3.9460e-01, -4.0466e-01,  4.0743e-01, -6.2202e-01, -2.6534e-01,\n","        -1.6051e-02,  4.3913e-01, -9.2362e-01,  3.6138e-01, -9.3469e-02,\n","         2.9467e-01, -6.1127e-01,  1.1618e-01, -2.8022e-01,  9.0463e-02,\n","         6.1543e-03,  9.1117e-02, -2.2541e-01,  6.4277e-01,  5.0465e-01,\n","        -1.2755e-01,  5.0909e-01,  2.9348e-01,  1.2239e-01,  3.0730e-02,\n","         1.6064e-01,  1.7079e-01, -5.5238e-02, -5.0800e-01, -2.8604e-01,\n","        -9.8293e-02, -4.2385e-03,  1.1644e-01, -1.4208e-01, -3.9435e-01,\n","        -3.8631e-01,  4.9814e-01,  7.4275e-01, -6.8219e-01, -2.1686e-01,\n","         3.0953e-01,  3.8892e-01, -7.5905e-01, -3.8677e-02, -8.5611e-02,\n","        -4.4929e-01, -2.3755e-01, -8.5069e-02, -1.4536e-01, -1.7305e-01,\n","         4.3572e-01, -2.5972e-01, -2.2706e-01,  1.8178e-01,  7.5155e-02,\n","        -1.2354e+00, -3.8477e-02, -3.4777e-01, -3.3714e-01, -3.4303e-01,\n","        -6.0490e-01, -5.4858e-02,  4.8774e-01,  7.0761e-01,  1.9615e-01,\n","        -4.9773e-01,  5.4514e-01, -7.5572e-01,  5.5635e-02, -1.7627e-02,\n","        -2.4722e-02,  4.0634e-02,  3.9997e-01,  2.6073e-01,  2.2043e-01,\n","         4.3057e-01, -3.4890e-01,  3.7281e-02,  5.0916e-01, -9.5202e-01,\n","         5.4603e-01, -6.4651e-01, -1.5760e-01,  5.8654e-01, -2.1129e-01,\n","        -2.0999e+00, -1.4028e-03,  5.1954e-01,  5.8836e-01,  5.4086e-01,\n","         2.6720e-03, -7.4071e-02,  2.5329e-01, -1.3651e-01,  4.9498e-01,\n","        -3.6194e-01, -1.7986e-01,  2.7265e-01,  5.9342e-02,  1.1412e-01,\n","         3.9827e-03,  1.0881e-01, -1.7636e-01,  8.3390e-02, -2.8881e-01,\n","        -1.0998e-01,  3.7504e-01,  3.4998e-01,  7.0962e-01,  2.8812e-01,\n","        -2.2239e-01, -3.0762e-02,  2.8323e-01, -1.0333e-01,  5.4158e-01,\n","         2.2385e-01, -6.3372e-01, -4.8591e-01, -1.0089e+00,  1.0880e+00,\n","         5.6704e-01,  4.3626e-02,  3.6383e-01, -2.0883e-01,  6.0793e-01,\n","        -3.0120e-01,  1.4469e-01,  9.3426e-01,  9.2225e-01,  7.0268e-03,\n","         3.4239e-02,  2.3744e-01, -1.4373e-02, -2.1905e-01, -1.5742e-01,\n","         3.2130e-01,  1.3797e-01,  3.0918e-02, -2.3620e-01, -4.9864e-01,\n","        -2.4249e-01, -3.5059e-01, -2.3377e-01, -8.1488e-01,  7.5947e-02,\n","         1.0669e+00,  1.0592e-01, -6.2600e-01, -2.6788e-01, -2.6539e-01,\n","        -4.1650e-01, -9.5066e-02, -1.2507e-01, -4.5494e-01,  6.4973e-01,\n","         4.1798e-01, -6.2822e-02, -7.9056e-01, -2.9883e-02,  9.3550e-02,\n","        -3.3613e-01, -1.9968e-01,  4.7394e-01,  3.5558e-01, -1.9931e-01,\n","         6.4410e-01, -5.6229e-01, -3.0334e-03,  6.0413e-01, -3.1644e-01,\n","         7.3956e-02, -2.3796e-01, -1.6798e-01,  5.5720e-01, -3.0203e-01,\n","        -1.4711e-01, -6.4964e-01,  4.9631e-01, -1.7784e-02,  1.9244e-01,\n","         1.2528e-02, -3.4845e-01, -2.1717e-01, -4.8768e-01,  7.8931e-02,\n","        -9.9124e-02, -1.5081e-01,  4.8844e-01, -1.1773e-01,  3.7841e-01,\n","         7.3059e-01,  2.2872e-01, -6.0538e-02, -3.2224e-01,  1.4177e-01,\n","         4.1905e-01,  8.1591e-02, -6.2040e-01,  6.1706e-01,  3.0352e-01,\n","        -2.9337e-01,  4.6226e-02, -7.4995e-01,  6.4087e-02,  1.8522e-02,\n","         2.5785e-01,  3.6435e-02,  2.7939e-01, -4.7244e-02, -1.4837e-01,\n","        -4.3425e-01, -1.7650e-01,  6.9357e-01, -5.6927e-01,  9.1171e-01,\n","        -2.5177e-01, -2.5150e-01,  6.5688e-01,  7.0479e-01,  3.0306e-01,\n","        -6.9310e-01, -8.0301e-01,  2.5094e-01, -3.9436e-01,  3.8376e-01,\n","         4.9443e-01, -6.8599e-01, -3.9733e-01,  2.1738e-01, -8.5134e-02,\n","         3.2225e-01,  9.1792e-02,  3.7680e-01,  1.4275e-01,  1.9375e-01,\n","        -7.2867e-02,  1.0137e+00, -3.6093e-01, -3.2844e-01, -4.7212e-01,\n","        -4.7861e-01, -1.8302e-01, -1.2180e-04, -4.2985e-01, -1.2398e-01,\n","         4.6820e-01, -2.4856e-01, -1.3760e-01,  6.5728e-01,  5.6275e-03,\n","        -4.2098e-01,  1.6346e-01,  7.7030e-01, -2.8659e-01, -5.8064e-01,\n","         1.0748e-01,  3.2548e-01, -6.4719e-02, -1.9482e-01, -4.1841e-01,\n","        -7.6163e-01, -5.1279e-01,  9.1793e-01, -4.4523e-01,  7.1406e-02,\n","         3.5033e-01, -4.7681e-01, -1.1784e-01,  6.8565e-02, -2.2953e-01,\n","         3.1152e-01,  2.9084e-01, -2.8166e-01,  3.5152e-02,  5.5383e-01,\n","         1.0160e+00,  6.2193e-01,  1.3250e-01,  6.0047e-01,  4.6697e-01,\n","        -7.6861e-01, -1.4042e-01, -2.0490e-01, -1.1983e-01,  3.7806e-02,\n","        -2.5424e-02, -4.4065e-02,  1.8069e-01,  1.5926e-01,  1.3611e-01,\n","         7.3470e-01, -3.0914e-01, -5.4038e-01,  6.8040e-01,  2.0963e-01,\n","        -2.0104e-01,  1.4587e-01, -4.4374e-01,  4.4258e-01, -9.4550e-03,\n","        -4.6953e-02, -3.8309e-01, -9.7250e-02, -1.8281e-01, -8.0588e-01,\n","        -3.9593e-01, -1.9447e-01,  7.8777e-01,  4.3225e-01,  2.5620e-02,\n","        -8.6586e-02, -1.1657e-01,  1.2488e-01,  4.2359e-01, -1.0062e-01,\n","        -4.5902e-01,  7.1786e-01,  2.1758e-01, -2.7604e-01, -2.5328e-01,\n","        -3.0193e-01,  4.6264e-01, -2.6710e-01,  6.6475e-01, -1.7954e-01,\n","         6.5488e-01,  3.6956e-01, -2.4965e-01,  3.9864e-01, -6.7488e-01,\n","         4.1960e-01, -4.2689e-01,  2.0901e-01,  3.8223e-02,  4.8119e-01,\n","         1.5156e-01,  6.7575e-01,  1.1677e-01, -8.1948e-02, -1.0540e-01,\n","         4.6403e-01,  1.5562e-01, -7.3558e-01, -6.8996e-02, -2.7774e-01,\n","         1.4826e-01,  3.3956e-01, -2.4024e-01, -5.4096e-01, -3.2693e-01,\n","        -7.6715e-01, -7.8082e-01, -2.4397e-01,  1.7152e-01,  1.4835e-01,\n","        -9.5983e-02,  2.2353e-01, -2.6013e-01, -2.2674e-01,  4.8688e-01,\n","         8.1931e-02, -1.0242e-01,  1.0640e-01, -1.7737e-01,  2.1931e-01,\n","        -1.3067e-01,  1.3798e-01, -1.4375e+00,  1.9847e-01, -2.1997e-01,\n","         2.1900e-01, -6.0209e-01, -7.3217e-01,  9.5402e-02, -5.5060e-01,\n","        -7.7929e-01, -6.4954e-01,  2.3006e-01, -6.5008e-01,  3.2119e-01,\n","        -1.8127e-02,  2.9258e-01, -3.1719e-01])"]},"metadata":{},"execution_count":15}]}]}